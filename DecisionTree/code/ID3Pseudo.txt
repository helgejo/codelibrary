   function ID3 (R: a set of non-categorical attributes,
		 C: the categorical attribute,
		 S: a training set) returns a decision tree;
   begin
	If S is empty, return a single node with value Failure;
	If S consists of records all with the same value for 
	   the categorical attribute, 
	   return a single node with that value;
	If R is empty, then return a single node with as value
	   the most frequent of the values of the categorical attribute
	   that are found in records of S; [note that then there
	   will be errors, that is, records that will be improperly
	   classified];
	Let D be the attribute with largest Gain(D,S) 
	   among attributes in R;
	Let {dj| j=1,2, .., m} be the values of attribute D;
	Let {Sj| j=1,2, .., m} be the subsets of S consisting 
	   respectively of records with value dj for attribute D;
	Return a tree with root labeled D and arcs labeled 
	   d1, d2, .., dm going respectively to the trees 

	     ID3(R-{D}, C, S1), ID3(R-{D}, C, S2), .., ID3(R-{D}, C, Sm);
   end ID3;
   
   
   id3(examples, attributes) 
   ''' 
   examples are the training examples.  attributes is a list of
   attributes that may be tested by the learned decison tree.  Returns
   a tree that correctly classifies the given examples. Assume that
   the targetAttribute, which is the attribute whose value is to be
   predicted by the tree, is a class variable.
   '''
   node = DecisionTreeNode(examples)
   # handle target attributes with arbitrary labels
   dictionary = summarizeExamples(examples, targetAttribute)
   for key in dictionary:
       if dictionary[key] == total number of examples
          node.label = key
          return node
   # test for number of examples to avoid overfitting
   if attributes is empty or number of examples < minimum allowed per branch:
      node.label = most common value in examples
      return node
   bestA = the attribute with the most information gain
   node.decision = bestA
   for each possible value v of bestA:
      subset = the subset of examples that have value v for bestA
      if subset is not empty:
         node.addBranch(id3(subset, targetAttribute, attributes-bestA))
   return node